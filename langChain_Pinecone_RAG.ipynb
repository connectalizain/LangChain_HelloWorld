{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPmGbtXiYzjJWhCuWVYogZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/connectalizain/LangChain_HelloWorld/blob/main/langChain_Pinecone_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r02AFx3CTqdB",
        "outputId": "a17ed3bd-3505-4a1d-84df-7fcc023ab88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('PINECONE_API_KEY')\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "klYJPd-zUDNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index_name = \"my-firstt-rag\"\n",
        "pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "aQikyDl5uuJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   768 is code from Google\n",
        "*   512/384 are other options but they use less data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v-I4ML6jJX6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "vector = embeddings.embed_query(\"hello, world!\")\n",
        "vector[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRuv_w75xfvo",
        "outputId": "377d5376-0b75-4af1-83c4-3ec5eb91e1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.014134909026324749,\n",
              " -0.022324152290821075,\n",
              " -0.054603420197963715,\n",
              " -0.006284549366682768,\n",
              " -0.03392402455210686]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "IC-GHh2wzWkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\" Owl,Whispers float through midnight air, Wisdom wrapped in a feathery glare.\",\n",
        "    metadata={\"source\": \"gpt\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"Cat, Silent steps and secret stares, Queen of calm and cozy lairs\",\n",
        "    metadata={\"source\": \"gpt\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"🐘 Elephant, With gentle grace and giant might, She walks like thunder, calm and bright.\",\n",
        "    metadata={\"source\": \"gpt\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ-y7Sj0zYkK",
        "outputId": "b8ec5b86-588c-4373-b447-379ad6a8d05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a64a23e7-5c23-4523-bcbf-5fe4cd4a9ea1',\n",
              " '27f8ecf9-a123-41ae-bb36-e6aedc5d9cba',\n",
              " '402eef35-e700-4668-9d84-37835e71de3c',\n",
              " 'c0158f34-5004-4bff-a5ab-5ec61610e17c',\n",
              " 'ef41810f-b4d7-4ea5-80e3-b0c56a3c6bae',\n",
              " 'b91f2374-49b2-4974-89d1-485b17376360',\n",
              " '831d4fa6-1d09-426a-b8f7-95ca754618be',\n",
              " 'a348b5b5-5f14-4b96-be70-5ab60d489e04',\n",
              " '124548e3-b880-4d7e-8449-b250e399c27f',\n",
              " '9ae60998-a5f5-421f-a0e0-7276a6b4b9dd']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUERY SEARCH WITH SIMILARITY\n",
        "\n",
        "\n",
        "*   K is used for number of answers you want\n",
        "*   FILTERS are used search data using key data pair\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "UEFMQWE7z47T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"poetry\",\n",
        "    # k=2,\n",
        "    filter={\"source\": \"gpt\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YneAcmhbzmM_",
        "outputId": "8f1e9d5a-9f76-4487-8688-b6e17b5adb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*  Owl,Whispers float through midnight air, Wisdom wrapped in a feathery glare. [{'source': 'gpt'}]\n",
            "* Dog, Loyal eyes and wagging tail, A heart so big, it’ll never fail. [{'source': 'gpt'}]\n",
            "* Dog, Loyal eyes and wagging tail, A heart so big, it’ll never fail. [{'source': 'gpt'}]\n",
            "* Dog, Loyal eyes and wagging tail, A heart so big, it’ll never fail. [{'source': 'gpt'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMILARITY SEARCH WITH SCORE"
      ],
      "metadata": {
        "id": "VCJ2rDEpz-6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=2, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MoOxTJT0DB_",
        "outputId": "d8129ecc-e2c7-436e-a61a-a491bfe25765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.639507] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n",
            "* [SIM=0.414024] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model= \"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "45hKwucNUN5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg\n",
        "print(f\"your result: {ai_msg.content} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoK9RpZgUkvY",
        "outputId": "78b3451a-160b-4bad-c9bf-fd45cee4dd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your result: That's great!  Programming is a rewarding and challenging field. What aspects of programming do you enjoy the most? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_to_user(query: str):\n",
        "  vector_results = vector_store.similarity_search( query,\n",
        "    k=2)\n",
        "  final_ans = llm.invoke(f\"please share more info regarding this {vector_results}\")\n",
        "  print(final_ans.content)"
      ],
      "metadata": {
        "id": "Njw8Ig10VP3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_to_user(\"elobrate this poetry about owl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6FDsVuSXVLR",
        "outputId": "725c86e5-e6cd-477b-ed6c-a0492f66b4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This data represents a list of two documents generated by GPT (likely a large language model like GPT-3 or GPT-4).  Let's break down each document:\n",
            "\n",
            "**Document 1:**\n",
            "\n",
            "* **`id='a64a23e7-5c23-4523-bcbf-5fe4cd4a9ea1'`**: This is a unique identifier for the document.  It's a universally unique identifier (UUID), ensuring that this document can be distinguished from any other.\n",
            "\n",
            "* **`metadata={'source': 'gpt'}`**: This metadata indicates the origin of the document.  `'gpt'` signifies that it was generated by a GPT model.\n",
            "\n",
            "* **`page_content=' Owl,Whispers float through midnight air, Wisdom wrapped in a feathery glare.'`**: This is the actual content of the document – a short, poetic description of an owl.  It uses imagery and metaphor to evoke a sense of mystery and wisdom.\n",
            "\n",
            "\n",
            "**Document 2:**\n",
            "\n",
            "* **`id='ad292e01-9b03-454a-80de-cbfd763a459b'`**:  Another unique identifier for this document.\n",
            "\n",
            "* **`metadata={'source': 'gpt'}`**:  Again, indicating GPT as the source.\n",
            "\n",
            "* **`page_content='🐘 Elephant, With gentle grace and giant might, She walks like thunder, calm and bright.'`**: This document contains a similar short poem, this time describing an elephant.  It highlights the animal's size, strength, and peaceful nature.  The use of \"She\" personifies the elephant.\n",
            "\n",
            "\n",
            "**Overall:**\n",
            "\n",
            "The data suggests a small corpus of text generated by GPT, likely as part of a larger project or experiment.  The poems are simple but evocative, demonstrating the model's ability to generate creative text based on a given subject (in this case, animals).  The inclusion of UUIDs suggests a system designed to manage and track multiple generated documents.  The metadata is crucial for understanding the context and origin of the data.\n"
          ]
        }
      ]
    }
  ]
}